{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-defined ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# \n",
    "# File Name : rouge.py\n",
    "#\n",
    "# Description : Computes ROUGE-L metric as described by Lin and Hovey (2004)\n",
    "#\n",
    "# Creation Date : 2015-01-07 06:03\n",
    "# Author : Ramakrishna Vedantam <vrama91@vt.edu>\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "def my_lcs(string, sub):\n",
    "    \"\"\"\n",
    "    Calculates longest common subsequence for a pair of tokenized strings\n",
    "    :param string : list of str : tokens from a string split using whitespace\n",
    "    :param sub : list of str : shorter string, also split using whitespace\n",
    "    :returns: length (list of int): length of the longest common subsequence between the two strings\n",
    "\n",
    "    Note: my_lcs only gives length of the longest common subsequence, not the actual LCS\n",
    "    \"\"\"\n",
    "    if(len(string)< len(sub)):\n",
    "        sub, string = string, sub\n",
    "\n",
    "    lengths = [[0 for i in range(0,len(sub)+1)] for j in range(0,len(string)+1)]\n",
    "\n",
    "    for j in range(1,len(sub)+1):\n",
    "        for i in range(1,len(string)+1):\n",
    "            if(string[i-1] == sub[j-1]):\n",
    "                lengths[i][j] = lengths[i-1][j-1] + 1\n",
    "            else:\n",
    "                lengths[i][j] = max(lengths[i-1][j] , lengths[i][j-1])\n",
    "\n",
    "    return lengths[len(string)][len(sub)]\n",
    "\n",
    "class Rouge():\n",
    "    '''\n",
    "    Class for computing ROUGE-L score for a set of candidate sentences for the MS COCO test set\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # vrama91: updated the value below based on discussion with Hovey\n",
    "        self.beta = 1.2\n",
    "\n",
    "    def calc_score(self, candidate, refs):\n",
    "        \"\"\"\n",
    "        Compute ROUGE-L score given one candidate and references for an image\n",
    "        :param candidate: str : candidate sentence to be evaluated\n",
    "        :param refs: list of str : COCO reference sentences for the particular image to be evaluated\n",
    "        :returns score: int (ROUGE-L score for the candidate evaluated against references)\n",
    "        \"\"\"\n",
    "        assert(len(candidate)==1)\t\n",
    "        assert(len(refs)>0)         \n",
    "        prec = []\n",
    "        rec = []\n",
    "\n",
    "        # split into tokens\n",
    "        token_c = candidate[0].split(\" \")\n",
    "    \t\n",
    "        for reference in refs:\n",
    "            # split into tokens\n",
    "            token_r = reference.split(\" \")\n",
    "            # compute the longest common subsequence\n",
    "            lcs = my_lcs(token_r, token_c)\n",
    "            prec.append(lcs/float(len(token_c)))\n",
    "            rec.append(lcs/float(len(token_r)))\n",
    "\n",
    "        prec_max = max(prec)\n",
    "        rec_max = max(rec)\n",
    "\n",
    "        if(prec_max!=0 and rec_max !=0):\n",
    "            score = ((1 + self.beta**2)*prec_max*rec_max)/float(rec_max + self.beta**2*prec_max)\n",
    "        else:\n",
    "            score = 0.0\n",
    "        return score\n",
    "\n",
    "    def compute_score(self, gts, res):\n",
    "        \"\"\"\n",
    "        Computes Rouge-L score given a set of reference and candidate sentences for the dataset\n",
    "        Invoked by evaluate_captions.py \n",
    "        :param hypo_for_image: dict : candidate / test sentences with \"image name\" key and \"tokenized sentences\" as values \n",
    "        :param ref_for_image: dict : reference MS-COCO sentences with \"image name\" key and \"tokenized sentences\" as values\n",
    "        :returns: average_score: float (mean ROUGE-L score computed by averaging scores for all the images)\n",
    "        \"\"\"\n",
    "        # assert(gts.keys() == res.keys())\n",
    "        # imgIds = gts.keys()\n",
    "        #\n",
    "        # score = []\n",
    "        # for id in imgIds:\n",
    "        #     hypo = res[id]\n",
    "        #     ref  = gts[id]\n",
    "\n",
    "        assert (len(gts) == len(res))\n",
    "\n",
    "        score = []\n",
    "        for idx in range(len(gts)):\n",
    "            hypo = [res[idx]]\n",
    "            ref  = [gts[idx]]\n",
    "\n",
    "            score.append(self.calc_score(hypo, ref))\n",
    "\n",
    "            # Sanity check.\n",
    "            assert(type(hypo) is list)\n",
    "            assert(len(hypo) == 1)\n",
    "            assert(type(ref) is list)\n",
    "            assert(len(ref) > 0)\n",
    "\n",
    "        average_score = np.mean(np.array(score))\n",
    "        return average_score, np.array(score)\n",
    "\n",
    "    def method(self):\n",
    "        return \"Rouge\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge=Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_path=\"/home/yued/phd/LRD/lrd_summ/result/textrank.txt\"\n",
    "ref_path=\"/home/yued/phd/LRD/lrd_summ/result/ref.txt\"\n",
    "with open(hyp_path,'r') as f:\n",
    "    hyps = f.readlines()\n",
    "with open(ref_path,'r') as f:\n",
    "    refs = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.18408339989737207, array([0.14124107, 0.18305173, 0.19205397, ..., 0.20318489, 0.17531193,\n",
      "       0.15565479]))\n"
     ]
    }
   ],
   "source": [
    "print(rouge.compute_score(refs,hyps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2050288622385424, array([0.1568215 , 0.19615274, 0.21642576, ..., 0.23908572, 0.19167629,\n",
      "       0.20697546]))\n"
     ]
    }
   ],
   "source": [
    "hyp_path=\"/home/yued/phd/LRD/lrd_summ/result/textrank.tokenized\"\n",
    "ref_path=\"/home/yued/phd/LRD/lrd_summ/result/ref.tokenized\"\n",
    "with open(hyp_path,'r') as f:\n",
    "    hyps = f.readlines()\n",
    "with open(ref_path,'r') as f:\n",
    "    refs = f.readlines()\n",
    "print(rouge.compute_score(refs,hyps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creare the data as pyrouge needs\n",
    "with open(\"/home/yued/phd/LRD/lrd_summ/result/textrank.txt\",'r') as f:\n",
    "    hyps=f.readlines()\n",
    "for i,h in enumerate(hyps):\n",
    "    with open(\"/home/yued/phd/LRD/lrd_summ/result/hyps/%d_decoded.txt\"%i,'w') as f:\n",
    "        if len(h)==0: #deal with empty lines\n",
    "            h='n'\n",
    "        f.write(h)\n",
    "\n",
    "with open(\"/home/yued/phd/LRD/lrd_summ/result/ref.txt\",'r') as f:\n",
    "    refs=f.readlines()\n",
    "for i,h in enumerate(refs):\n",
    "    with open(\"/home/yued/phd/LRD/lrd_summ/result/refs/%d_reference.txt\"%i,'w') as f:\n",
    "        f.write(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Cannot set system directory because the path decoded/ does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2b4d231a686b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRouge155\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# set directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'decoded/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'reference/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyrouge/Rouge155.py\u001b[0m in \u001b[0;36mfset\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mverify_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyrouge/utils/file_utils.py\u001b[0m in \u001b[0;36mverify_dir\u001b[0;34m(path, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}he path {} does not exist.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Cannot set system directory because the path decoded/ does not exist."
     ]
    }
   ],
   "source": [
    "from pyrouge import Rouge155\n",
    "r = Rouge155()\n",
    "# set directories\n",
    "r.system_dir = \"/home/yued/phd/LRD/lrd_summ/result/hyps/\"\n",
    "r.model_dir = \"/home/yued/phd/LRD/lrd_summ/result/refs/\"\n",
    " \n",
    "# define the patterns\n",
    "r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
    "r.model_filename_pattern = '#ID#_reference.txt'\n",
    " \n",
    "# use default parameters to run the evaluation\n",
    "output = r.convert_and_evaluate()\n",
    "print(output)\n",
    "output_dict = r.output_to_dict(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file2rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import files2rouge\n",
    "files2rouge.run(hyp_path, ref_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
