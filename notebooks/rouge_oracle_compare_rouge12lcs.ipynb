{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def lines2df(lines):\n",
    "    ex_dicts = []\n",
    "    for line in lines:\n",
    "        ex_dict = json.loads(line.strip())\n",
    "        ex_dicts.append(ex_dict)\n",
    "    df = pd.DataFrame.from_records(ex_dicts, columns=list(ex_dicts[0].keys()))\n",
    "    return df\n",
    "\n",
    "# lines = [l for l in open('/home/ubuntu/efs/lei/emerald_new/emerald.jsonl', 'r').readlines()]\n",
    "lines = [l for l in open('/home/ubuntu/efs/lei/emerald_new/test.jsonl', 'r').readlines()]\n",
    "\n",
    "emerald_df = lines2df(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_paragraph(sections):\n",
    "    return '\\n'.join(j for i in sections for j in i)\n",
    "emerald_df['fulltext'] = emerald_df.sections.apply(concat_paragraph)\n",
    "emerald_df['abstracttext'] = emerald_df.abstract_sections.apply(concat_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_section_title_like(section_names, section_text, cuewords):\n",
    "    text = []\n",
    "    for sn, st in zip(section_names, section_text):\n",
    "        sn = sn.lower()\n",
    "        for cueword in cuewords:\n",
    "            if cueword in sn:\n",
    "                text.append(' '.join(st))\n",
    "                break\n",
    "    return ' '.join(text)\n",
    "\n",
    "def find_section_title_not_like(section_names, section_text, cuewords):\n",
    "    text = []\n",
    "    for sn, st in zip(section_names, section_text):\n",
    "        sn = sn.lower()\n",
    "        positive = False\n",
    "        for cueword in cuewords:\n",
    "            if cueword in sn:\n",
    "                positive = True\n",
    "                break\n",
    "        if not positive:\n",
    "            text.append(' '.join(st))\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "emerald_df['source_introduction'] = emerald_df.apply(lambda row: find_section_title_like(row['section_names'], row['sections'], ['intro', 'purpose']), axis=1)\n",
    "emerald_df['source_design'] = emerald_df.apply(lambda row: find_section_title_like(row['section_names'], row['sections'], ['design', 'method', 'approach']), axis=1)\n",
    "emerald_df['source_result'] = emerald_df.apply(lambda row: find_section_title_like(row['section_names'], row['sections'], ['result', 'find', 'discuss', 'analy']), axis=1)\n",
    "emerald_df['source_conclusion'] = emerald_df.apply(lambda row: find_section_title_like(row['section_names'], row['sections'], ['conclu', 'future']), axis=1)\n",
    "emerald_df['source_related'] = emerald_df.apply(lambda row: find_section_title_like(row['section_names'], row['sections'], ['related work', 'literat', 'background']), axis=1)\n",
    "\n",
    "emerald_df['source_loo_introduction'] = emerald_df.apply(lambda row: find_section_title_not_like(row['section_names'], row['sections'], ['intro', 'purpose']), axis=1)\n",
    "emerald_df['source_loo_design'] = emerald_df.apply(lambda row: find_section_title_not_like(row['section_names'], row['sections'], ['design', 'method', 'approach']), axis=1)\n",
    "emerald_df['source_loo_result'] = emerald_df.apply(lambda row: find_section_title_not_like(row['section_names'], row['sections'], ['result', 'find', 'discuss', 'analy']), axis=1)\n",
    "emerald_df['source_loo_conclusion'] = emerald_df.apply(lambda row: find_section_title_not_like(row['section_names'], row['sections'], ['conclu', 'future']), axis=1)\n",
    "emerald_df['source_loo_related'] = emerald_df.apply(lambda row: find_section_title_not_like(row['section_names'], row['sections'], ['related work', 'literat', 'background']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emerald_df['source_IC'] = emerald_df['source_introduction'] + ' ' + emerald_df['source_conclusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('Purpose', 'Design/methodology/approach', 'Findings', 'Originality/value')\n",
    "emerald_df['target_introduction'] = emerald_df.apply(lambda row: find_section_title_like(row['abstract_sections_names'], row['abstract_sections'],\n",
    "                                                                                         ['Purpose'.lower()]), axis=1)\n",
    "emerald_df['target_design'] = emerald_df.apply(lambda row: find_section_title_like(row['abstract_sections_names'], row['abstract_sections'],\n",
    "                                                                                   ['Design/methodology/approach'.lower()]), axis=1)\n",
    "emerald_df['target_findings'] = emerald_df.apply(lambda row: find_section_title_like(row['abstract_sections_names'], row['abstract_sections'],\n",
    "                                                                                     ['Findings'.lower()]), axis=1)\n",
    "emerald_df['target_originality'] = emerald_df.apply(lambda row: find_section_title_like(row['abstract_sections_names'], row['abstract_sections'],\n",
    "                                                                                        ['Originality/value'.lower()]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_names</th>\n",
       "      <th>sections</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>source_IC</th>\n",
       "      <th>source_introduction</th>\n",
       "      <th>source_design</th>\n",
       "      <th>source_result</th>\n",
       "      <th>source_conclusion</th>\n",
       "      <th>source_related</th>\n",
       "      <th>source_loo_introduction</th>\n",
       "      <th>source_loo_design</th>\n",
       "      <th>source_loo_result</th>\n",
       "      <th>source_loo_conclusion</th>\n",
       "      <th>source_loo_related</th>\n",
       "      <th>abstracttext</th>\n",
       "      <th>target_introduction</th>\n",
       "      <th>target_design</th>\n",
       "      <th>target_findings</th>\n",
       "      <th>target_originality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1. Introduction, 2. Writing qualitatively in ...</td>\n",
       "      <td>[[The increasing institutional pressure to pub...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>Our aim was to unearth data from like-minded c...</td>\n",
       "      <td>Reading, and re-reading, the questions and ans...</td>\n",
       "      <td>Figure 3 pulls together the various patterned ...</td>\n",
       "      <td></td>\n",
       "      <td>Research in the areas of entrepreneurship and ...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>The increasing institutional pressure to publi...</td>\n",
       "      <td>- The purpose of this paper is to report on a ...</td>\n",
       "      <td>- The purpose of this paper is to report on a ...</td>\n",
       "      <td>- Scholars who had published qualitative paper...</td>\n",
       "      <td>- Entrepreneurship scholars perceive their qua...</td>\n",
       "      <td>- Although there is a vigorous debate within t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1. Introduction, 2. Literature review and hyp...</td>\n",
       "      <td>[[Today's manufacturing companies are far more...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>The implementation of LM and FMS in US automot...</td>\n",
       "      <td>4.1 Measurement model assessment Four tests we...</td>\n",
       "      <td>Ambiguity, uncertainty and complexity are just...</td>\n",
       "      <td>LM, also known as the Toyota Production System...</td>\n",
       "      <td>LM, also known as the Toyota Production System...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>Today's manufacturing companies are far more a...</td>\n",
       "      <td>The purpose of this paper is to identify the m...</td>\n",
       "      <td>The purpose of this paper is to identify the m...</td>\n",
       "      <td>A survey questionnaire was developed based on ...</td>\n",
       "      <td>Lean and FMS are multi-dimensional philosophie...</td>\n",
       "      <td>This research empirically develops a framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Introduction, Methodology, Case description, ...</td>\n",
       "      <td>[[In the last 20 years, there has been a drama...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>Study design We chose an in-depth case study a...</td>\n",
       "      <td>Empirical patterns In the chain of pre-merger ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Study design We chose an in-depth case study a...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>In the last 20 years, there has been a dramati...</td>\n",
       "      <td>- The purpose of this paper is to examine how ...</td>\n",
       "      <td>- The purpose of this paper is to examine how ...</td>\n",
       "      <td>- Based on extensive document analysis and 35 ...</td>\n",
       "      <td>- Spanning nearly a decade, the pre-merger pro...</td>\n",
       "      <td>- This is the first systematic in-depth study ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       section_names  \\\n",
       "0  [1. Introduction, 2. Writing qualitatively in ...   \n",
       "1  [1. Introduction, 2. Literature review and hyp...   \n",
       "2  [Introduction, Methodology, Case description, ...   \n",
       "\n",
       "                                            sections  \\\n",
       "0  [[The increasing institutional pressure to pub...   \n",
       "1  [[Today's manufacturing companies are far more...   \n",
       "2  [[In the last 20 years, there has been a drama...   \n",
       "\n",
       "                                            fulltext  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                           source_IC  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                 source_introduction  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                       source_design  \\\n",
       "0  Our aim was to unearth data from like-minded c...   \n",
       "1  The implementation of LM and FMS in US automot...   \n",
       "2  Study design We chose an in-depth case study a...   \n",
       "\n",
       "                                       source_result  \\\n",
       "0  Reading, and re-reading, the questions and ans...   \n",
       "1  4.1 Measurement model assessment Four tests we...   \n",
       "2  Empirical patterns In the chain of pre-merger ...   \n",
       "\n",
       "                                   source_conclusion  \\\n",
       "0  Figure 3 pulls together the various patterned ...   \n",
       "1  Ambiguity, uncertainty and complexity are just...   \n",
       "2                                                      \n",
       "\n",
       "                                      source_related  \\\n",
       "0                                                      \n",
       "1  LM, also known as the Toyota Production System...   \n",
       "2                                                      \n",
       "\n",
       "                             source_loo_introduction  \\\n",
       "0  Research in the areas of entrepreneurship and ...   \n",
       "1  LM, also known as the Toyota Production System...   \n",
       "2  Study design We chose an in-depth case study a...   \n",
       "\n",
       "                                   source_loo_design  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                   source_loo_result  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                               source_loo_conclusion  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                  source_loo_related  \\\n",
       "0  The increasing institutional pressure to publi...   \n",
       "1  Today's manufacturing companies are far more a...   \n",
       "2  In the last 20 years, there has been a dramati...   \n",
       "\n",
       "                                        abstracttext  \\\n",
       "0  - The purpose of this paper is to report on a ...   \n",
       "1  The purpose of this paper is to identify the m...   \n",
       "2  - The purpose of this paper is to examine how ...   \n",
       "\n",
       "                                 target_introduction  \\\n",
       "0  - The purpose of this paper is to report on a ...   \n",
       "1  The purpose of this paper is to identify the m...   \n",
       "2  - The purpose of this paper is to examine how ...   \n",
       "\n",
       "                                       target_design  \\\n",
       "0  - Scholars who had published qualitative paper...   \n",
       "1  A survey questionnaire was developed based on ...   \n",
       "2  - Based on extensive document analysis and 35 ...   \n",
       "\n",
       "                                     target_findings  \\\n",
       "0  - Entrepreneurship scholars perceive their qua...   \n",
       "1  Lean and FMS are multi-dimensional philosophie...   \n",
       "2  - Spanning nearly a decade, the pre-merger pro...   \n",
       "\n",
       "                                  target_originality  \n",
       "0  - Although there is a vigorous debate within t...  \n",
       "1  This research empirically develops a framework...  \n",
       "2  - This is the first systematic in-depth study ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emerald_df = emerald_df[['section_names', 'sections', 'fulltext', 'source_IC',\n",
    "                         'source_introduction', 'source_design', 'source_result',\n",
    "                         'source_conclusion', 'source_related',\n",
    "                         'source_loo_introduction', 'source_loo_design',\n",
    "                         'source_loo_result', 'source_loo_conclusion', 'source_loo_related',\n",
    "                         'abstracttext',\n",
    "                         'target_introduction', 'target_design', 'target_findings', 'target_originality']]\n",
    "emerald_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emerald_df = emerald_df[['fulltext', 'abstracttext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy https://github.com/memray/bigsum\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import spacy\n",
    "from helper import rouge\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from helper import rouge_score\n",
    "\n",
    "def rouge1(evaluated_sentences, reference_sentences):\n",
    "    return rouge_score.rouge_n(evaluated_sentences, reference_sentences, n=1, stopwords_removal=False, stemming=False, punctuations_removal=False)['f']\n",
    "\n",
    "def rouge2(evaluated_sentences, reference_sentences):\n",
    "    return rouge_score.rouge_n(evaluated_sentences, reference_sentences, n=2, stopwords_removal=False, stemming=False, punctuations_removal=False)['f']\n",
    "\n",
    "def lcs(X, Y):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "\n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None] * (n + 1) for i in range(m + 1)]\n",
    "\n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion \n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1] \n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                L[i][j] = 0\n",
    "            elif X[i - 1] == Y[j - 1]:\n",
    "                L[i][j] = L[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
    "\n",
    "                # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    return L[m][n]\n",
    "\n",
    "def oracle_extract(sents, summary_sents, rouge_method, lower=True, stemming=True):\n",
    "    match_idx = []\n",
    "    match_title = []\n",
    "    match_scores = []\n",
    "\n",
    "    # lowercase\n",
    "    if lower:\n",
    "        sents = [[w.lower() for w in sent] for sent in sents]\n",
    "        summary_sents = [[w.lower() for w in sent] for sent in summary_sents]\n",
    "    # stemming\n",
    "    if stemming:\n",
    "        sents = [[stemmer.stem(w) for w in sent] for sent in sents]\n",
    "        summary_sents = [[stemmer.stem(w) for w in sent] for sent in summary_sents]\n",
    "\n",
    "    for summary_id, summary_sent in enumerate(summary_sents):\n",
    "        # rarely happens, number of summaries is larger than sents\n",
    "        if summary_id >= len(sents):\n",
    "            break\n",
    "\n",
    "        match_score = [rouge_method(sent, summary_sent) for sent in sents]\n",
    "\n",
    "        # remove the previously selected sents by setting their scores to 0\n",
    "        for match_id in match_idx:\n",
    "            match_score[match_id] = 0\n",
    "\n",
    "        match_id = np.argmax(match_score)\n",
    "        match_idx.append(match_id)\n",
    "        match_scores.append(match_score[match_id])\n",
    "\n",
    "    return match_idx, match_scores\n",
    "\n",
    "\n",
    "def eval_rouge(sents, summary_sents, extract_sent_idx, number_to_cutoff=3, stopwords_removal=False, stemming=True, logger=None):\n",
    "    rouge_ = rouge.Rouge(stopwords_removal=stopwords_removal, stemming=stemming)\n",
    "    # extract_sent_idx = extract_sent_idx[: min(number_to_cutoff, len(extract_sent_idx))]\n",
    "    # sort extracted sentences in the order of their appearance\n",
    "    # extract_sent_idx = sorted(extract_sent_idx)\n",
    "    extracted_sents = [sents[idx] for idx in extract_sent_idx if idx < len(sents)]\n",
    "    hypothesis = ' '.join(' '.join(i) for i in extracted_sents)\n",
    "    reference = summary_sents\n",
    "\n",
    "    if hypothesis == None or reference == None or len(hypothesis.strip()) == 0 or len(reference.strip()) == 0:\n",
    "        fscores = {k: 0.0 for k in metric_keys}\n",
    "    else:\n",
    "        scores = rouge_.get_scores(hypothesis, reference)\n",
    "        fscores = {k: v['f'] for k, v in scores[0].items()}\n",
    "\n",
    "    return fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# spacy_nlp = spacy.load('en_core_web_sm')\n",
    "from pysbd.utils import PySBDFactory\n",
    "spacy_nlp = spacy.blank('en')\n",
    "spacy_nlp.add_pipe(PySBDFactory(spacy_nlp))\n",
    "\n",
    "def oracle_score(section_text, abstract_text, rouge_method):\n",
    "    source_sents = [[w.text for w in sent] for sent in spacy_nlp(section_text).sents]\n",
    "    target_sents = [[w.text for w in sent] for sent in spacy_nlp(abstract_text).sents]\n",
    "\n",
    "    extract_sent_idx, _ = oracle_extract(source_sents, target_sents, rouge_method)\n",
    "\n",
    "    score = eval_rouge(source_sents,\n",
    "                       ' '.join(w for sent in target_sents for w in sent),\n",
    "                       extract_sent_idx)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [11:32<00:00,  8.66it/s]\n",
      "100%|██████████| 6000/6000 [11:20<00:00,  8.82it/s]\n",
      "100%|██████████| 6000/6000 [25:13<00:00,  3.97it/s] \n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.setrecursionlimit(25000)\n",
    "\n",
    "def func_lcs(i):\n",
    "    return oracle_score(emerald_df['fulltext'][i], emerald_df['abstracttext'][i], lcs)\n",
    "def func_rouge1(i):\n",
    "    return oracle_score(emerald_df['fulltext'][i], emerald_df['abstracttext'][i], rouge1)\n",
    "def func_rouge2(i):\n",
    "    return oracle_score(emerald_df['fulltext'][i], emerald_df['abstracttext'][i], rouge2)\n",
    "\n",
    "scores = {}\n",
    "\n",
    "p = Pool(10)\n",
    "\n",
    "for fn, f in (('rouge1', func_rouge1), ('rouge2', func_rouge2), ('lcs', func_lcs)):\n",
    "    limit = emerald_df.shape[0]\n",
    "    scores[fn] = []\n",
    "    r = p.imap_unordered(f, list(range(limit)), chunksize=10)\n",
    "    for score in tqdm(r, total=limit):\n",
    "        scores[fn].append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# json.dump(scores, open('oracle_score_testset_cmp_lcs_rouge.json', 'w'))\n",
    "scores = json.load(open('oracle_score_testset_cmp_lcs_rouge.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge-1    0.502001\n",
       "rouge-2    0.276558\n",
       "rouge-l    0.344522\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(scores['lcs'], columns=list(scores['lcs'][0].keys())).describe().loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge-1    0.585794\n",
       "rouge-2    0.328724\n",
       "rouge-l    0.448089\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(scores['rouge1'], columns=list(scores['lcs'][0].keys())).describe().loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge-1    0.571981\n",
       "rouge-2    0.344526\n",
       "rouge-l    0.441829\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(scores['rouge2'], columns=list(scores['lcs'][0].keys())).describe().loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4661/6000 [2:33:58<38:31,  1.73s/it]  "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.setrecursionlimit(25000)\n",
    "\n",
    "\n",
    "def rougeL(evaluated_sentences, reference_sentences):\n",
    "    return rouge_score.rouge_l_summary_level(evaluated_sentences, reference_sentences, stopwords_removal=False, stemming=False, punctuations_removal=False)['f']\n",
    "\n",
    "def func_rougeL(i):\n",
    "    return oracle_score(emerald_df['fulltext'][i], emerald_df['abstracttext'][i], rougeL)\n",
    "p = Pool(11)\n",
    "fn, f = 'rougeL', func_rougeL\n",
    "limit = emerald_df.shape[0]\n",
    "scores[fn] = []\n",
    "r = p.imap_unordered(f, list(range(limit)), chunksize=10)\n",
    "for score in tqdm(r, total=limit):\n",
    "    scores[fn].append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(scores['rougeL'], columns=list(scores['lcs'][0].keys())).describe().loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(scores, open('oracle_score_testset_cmp_lcs_rouge.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# import sys\n",
    "# # fix a issue in rouge code\n",
    "# sys.setrecursionlimit(25000)\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# tasks = []\n",
    "# for src_col in ('fulltext', 'source_introduction', 'source_design', 'source_result',\n",
    "#                 'source_conclusion', 'source_related'\n",
    "#                 'source_loo_introduction', 'source_loo_design', 'source_loo_result',\n",
    "#                 'source_loo_conclusion', 'source_loo_related'):\n",
    "#     for target_col in ('target_introduction', 'target_design', 'target_findings', 'target_originality'):\n",
    "#         task_name = '_TO_'.join((src_col, target_col))\n",
    "#         tasks.append((src_col, target_col, task_name))\n",
    "        \n",
    "# def func(a):\n",
    "#     src_col, target_col, task_name = a\n",
    "#     task_scores = []\n",
    "#     for i in range(emerald_df.shape[0]):\n",
    "#         src_text = emerald_df[src_col][i]\n",
    "#         if not src_text.strip():\n",
    "#             src_text = emerald_df['fulltext'][i]\n",
    "#         r = oracle_score(src_text, emerald_df[target_col][i], None) ## TODO\n",
    "#         task_scores.append(r)\n",
    "#     return task_name, task_scores\n",
    "\n",
    "# p = Pool(10)\n",
    "\n",
    "# scores = {}\n",
    "# r = p.imap_unordered(func, tasks, chunksize=1)\n",
    "# for task_name, task_scores in tqdm(r, total=len(tasks)):\n",
    "#     scores[task_name] = task_scores\n",
    "\n",
    "##################################\n",
    "# df_scores = []\n",
    "# for col in scores:\n",
    "#     df_score = pd.DataFrame.from_records(scores[col], columns=list(scores[col][0].keys())).describe()\n",
    "#     df_score.columns = [col + '-' + i for i in df_score.columns]\n",
    "#     df_scores.append(df_score)\n",
    "# df_score = pd.concat(df_scores, axis=1)\n",
    "# df_score\n",
    "############################\n",
    "# tmp = {}\n",
    "# for col in df_score.columns:\n",
    "#     src, tgt = col.split('_TO_')\n",
    "#     if src not in tmp:\n",
    "#         tmp[src] = {}\n",
    "#     tmp[src][tgt] = df_score[col]['mean']\n",
    "# df_cmp = pd.DataFrame(tmp)\n",
    "# df_cmp.sort_index(key=lambda x: x.str[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
