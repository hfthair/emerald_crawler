{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# In this file we prprocess the jsonl files to generate `.source` and `.target` file pairs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Find sections with by title. Return \"<|Title|>+Text\"\r\n",
    "def find_section_title_like(j, cuewords):\r\n",
    "    section_names, section_text = j['section_names'], j['sections']\r\n",
    "    text = []\r\n",
    "    for sn, st in zip(section_names, section_text):\r\n",
    "        sn = sn.lower()\r\n",
    "        for cueword in cuewords:\r\n",
    "            if cueword in sn:\r\n",
    "                text.append(f\"<|{sn.strip()}|>\")\r\n",
    "                text.append(' '.join(st))\r\n",
    "                break\r\n",
    "    return ' '.join(text)\r\n",
    "\r\n",
    "## Titles examples:\r\n",
    "# 'source_introduction' ['intro', 'purpose']\r\n",
    "# 'source_design' ['design', 'method', 'approach']\r\n",
    "# 'source_result' ['result', 'find', 'discuss', 'analy']\r\n",
    "# 'source_conclusion' ['conclu', 'future']\r\n",
    "# 'source_related' ['related work', 'literat', 'background']\r\n",
    "\r\n",
    "# find intro section, select first section if intro doesn't exist\r\n",
    "def get_intro_text(j):\r\n",
    "    intro_text = find_section_title_like(j, ['intro', 'purpose']).strip()\r\n",
    "    if not intro_text:\r\n",
    "        section_names, section_text = j['section_names'], j['sections']\r\n",
    "        if section_names and section_names[0] != '__NO_TITLE__':\r\n",
    "            intro_text = intro_text + ' ' + section_names[0]\r\n",
    "        if section_text:\r\n",
    "            intro_text = intro_text + ' ' + ' '.join(section_text[0])\r\n",
    "        intro_text = intro_text.strip()\r\n",
    "    return intro_text\r\n",
    "\r\n",
    "# find conclu section, select last section if conclu doesn't exist\r\n",
    "def get_conclu_text(j):\r\n",
    "    conclu_text = find_section_title_like(j, ['conclu', 'future']).strip()\r\n",
    "    if not conclu_text:\r\n",
    "        section_names, section_text = j['section_names'], j['sections']\r\n",
    "        if section_names and section_names[-1] != '__NO_TITLE__':\r\n",
    "            conclu_text = conclu_text + ' ' + section_names[-1]\r\n",
    "        if section_text:\r\n",
    "            conclu_text = conclu_text + ' ' + ' '.join(section_text[-1])\r\n",
    "        conclu_text = conclu_text.strip()\r\n",
    "    return conclu_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Get Intro+Conclu as source.\r\n",
    "def get_source_IC(j):\r\n",
    "    return ' '.join((get_intro_text(j), get_conclu_text(j))).replace('\\n', ' ').strip()\r\n",
    "\r\n",
    "# Get full text as source.\r\n",
    "def get_source_str(j):\r\n",
    "    sec_titles = j['section_names']\r\n",
    "    sections = j['sections']\r\n",
    "    r = []\r\n",
    "    for title, sec in zip(sec_titles, sections):\r\n",
    "        if title and title != '__NO_TITLE__':\r\n",
    "            r.append(f\"<|{title.strip()}|>\")\r\n",
    "        for par in sec:\r\n",
    "            r.append(par)\r\n",
    "            r.append(\"<|par|>\")\r\n",
    "    return ' '.join(r).replace('\\n', ' ').strip()\r\n",
    "\r\n",
    "# Get full text abstract as target.\r\n",
    "def get_target_str(j):\r\n",
    "    abstract_sections_names = j['abstract_sections_names']\r\n",
    "    abstract_sections = j['abstract_sections']\r\n",
    "    \r\n",
    "    title2section = dict(zip(abstract_sections_names, abstract_sections))\r\n",
    "    r = []\r\n",
    "    for title in ('Purpose', 'Design/methodology/approach', 'Findings', 'Originality/value'):\r\n",
    "        section = title2section[title]\r\n",
    "\r\n",
    "        title = title.split('/')[0]\r\n",
    "        r.append(f\"<|{title}|>\")\r\n",
    "\r\n",
    "        for par in section:\r\n",
    "            r.append(par)\r\n",
    "    return ' '.join(r).replace('\\n', ' ').strip()\r\n",
    "\r\n",
    "# Get only 4 sections: 'Purpose', 'Design/methodology/approach', 'Findings', 'Originality/value' as targets.\r\n",
    "def get_target_sections(j):\r\n",
    "    abstract_sections_names = j['abstract_sections_names']\r\n",
    "    abstract_sections = j['abstract_sections']\r\n",
    "    \r\n",
    "    title2section = dict(zip(abstract_sections_names, abstract_sections))\r\n",
    "    r = []\r\n",
    "    for title in ('Purpose', 'Design/methodology/approach', 'Findings', 'Originality/value'):\r\n",
    "        section = title2section[title]\r\n",
    "\r\n",
    "        title = title.split('/')[0]\r\n",
    "        \r\n",
    "        r.append((\r\n",
    "            title,\r\n",
    "            ' '.join(section).replace('\\n', ' ').strip()\r\n",
    "        ))\r\n",
    "    return r\r\n",
    "\r\n",
    "\r\n",
    "# Generate .source and .target files. (source_extractor -> full text abstract)\r\n",
    "# Use func_get_source_str to extract source.\r\n",
    "# Use get_target_str to extract targes: full abstract target.\r\n",
    "def generate_combined_data(src_dir, dst_dir, func_get_source_str=get_source_str):\r\n",
    "    def jsonl2data(src, dst):\r\n",
    "        f = open(src, encoding='utf8')\r\n",
    "        source_out = open(f\"{dst}.source\", 'w', encoding='utf8')\r\n",
    "        target_out = open(f\"{dst}.target\", 'w', encoding='utf8')\r\n",
    "        for line in f:\r\n",
    "            j = json.loads(line.strip())\r\n",
    "            s = func_get_source_str(j)\r\n",
    "            t = get_target_str(j)\r\n",
    "            source_out.write(s + '\\n')\r\n",
    "            target_out.write(t + '\\n')\r\n",
    "    for fname in ('train', 'dev', 'test'):\r\n",
    "        src = os.path.join(src_dir, f\"{fname}.jsonl\")\r\n",
    "        dst = os.path.join(dst_dir, fname)\r\n",
    "        print(f\"writing from \\n  :{src} to \\n  :{dst}\")\r\n",
    "        jsonl2data(src, dst)\r\n",
    "        \r\n",
    " \r\n",
    "# Generate .source and .target files. (source_extractor -> sections of abstract)\r\n",
    "# Use func_get_source_str to extract source.\r\n",
    "# Use get_target_sections to extract targes: sections of abstract.       \r\n",
    "def generate_seperate_data(src_dir, dst_dir, func_get_source_str=get_source_str):\r\n",
    "    def jsonl2data(src, dst):\r\n",
    "        f = open(src, encoding='utf8')\r\n",
    "        source_out = open(f\"{dst}.source\", 'w', encoding='utf8')\r\n",
    "        target_out = open(f\"{dst}.target\", 'w', encoding='utf8')\r\n",
    "        for line in f:\r\n",
    "            j = json.loads(line.strip())\r\n",
    "            s = func_get_source_str(j)\r\n",
    "            ts = get_target_sections(j)\r\n",
    "            for title, t in ts:\r\n",
    "                source_out.write(f\"<|{title}|> \" + s + '\\n')\r\n",
    "                target_out.write(t + '\\n')\r\n",
    "    for fname in ('train', 'dev', 'test'):\r\n",
    "        src = os.path.join(src_dir, f\"{fname}.jsonl\")\r\n",
    "        dst = os.path.join(dst_dir, fname)\r\n",
    "        print(f\"writing from \\n  :{src} to \\n  :{dst}\")\r\n",
    "        jsonl2data(src, dst)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "! mkdir /home/ubuntu/efs/emerald/data_ic_to_combined_target/\r\n",
    "! mkdir /home/ubuntu/efs/emerald/data_ic_to_seperate_target/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "generate_combined_data('/home/ubuntu/efs/emerald/', '/home/ubuntu/efs/emerald/data_ic_to_combined_target/', func_get_source_str=get_source_IC)\r\n",
    "generate_seperate_data('/home/ubuntu/efs/emerald/', '/home/ubuntu/efs/emerald/data_ic_to_seperate_target/', func_get_source_str=get_source_IC)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/train.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_combined_target/train\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/dev.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_combined_target/dev\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/test.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_combined_target/test\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/train.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_seperate_target/train\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/dev.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_seperate_target/dev\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/test.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_ic_to_seperate_target/test\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "l = []\r\n",
    "for fn in ('train', 'dev', 'test'):\r\n",
    "    with open('/home/ubuntu/efs/emerald/data_ic_to_combined_target/{}.source'.format(fn), 'r') as f:\r\n",
    "        l = l + [len(line.split(' ')) for line in f]\r\n",
    "import pandas as pd\r\n",
    "pd.DataFrame({'l': l}).describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  l\n",
       "count  60024.000000\n",
       "mean    1425.079951\n",
       "std      872.231249\n",
       "min       27.000000\n",
       "25%      880.000000\n",
       "50%     1261.000000\n",
       "75%     1778.000000\n",
       "max    33336.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1425.079951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>872.231249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# generate_combined_data('/home/ubuntu/efs/emerald/', '/home/ubuntu/efs/emerald/data_combined_target/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/train.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_combined_target/train\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/dev.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_combined_target/dev\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/test.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_combined_target/test\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# generate_seperate_data('/home/ubuntu/efs/emerald/', '/home/ubuntu/efs/emerald/data_seperate_target/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/train.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_seperate_target/train\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/dev.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_seperate_target/dev\n",
      "writing from \n",
      "  :/home/ubuntu/efs/emerald/test.jsonl to \n",
      "  :/home/ubuntu/efs/emerald/data_seperate_target/test\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}